{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 13:41:55,724\tWARNING compression.py:16 -- lz4 not available, disabling sample compression. This will significantly impact RLlib performance. To install lz4, run `pip install lz4`.\n",
      "2025-02-17 13:42:01,423\tINFO worker.py:1841 -- Started a local Ray instance.\n",
      "2025-02-17 13:42:04,357\tWARNING deprecation.py:50 -- DeprecationWarning: `config.training(num_sgd_iter=..)` has been deprecated. Use `config.training(num_epochs=..)` instead. This will raise an error in the future!\n",
      "2025-02-17 13:42:04,360\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "c:\\Python312\\Lib\\site-packages\\gymnasium\\spaces\\box.py:235: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\gymnasium\\spaces\\box.py:305: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:134: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float32, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Python312\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:158: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-02-17 13:42:19</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:15.50        </td></tr>\n",
       "<tr><td>Memory:      </td><td>13.9/15.7 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_4x4grid_e1e2f_00000</td><td style=\"text-align: right;\">           1</td><td>C:/Users/shrof/AppData/Local/Temp/ray/session_2025-02-17_13-41-58_169966_24992/artifacts/2025-02-17_13-42-04/PPO/driver_artifacts/PPO_4x4grid_e1e2f_00000_0_2025-02-17_13-42-04/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_4x4grid_e1e2f_00000</td><td>ERROR   </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 13:42:04,473\tWARNING algorithm_config.py:4726 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "2025-02-17 13:42:04,473\tWARNING algorithm_config.py:4726 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "\u001b[36m(pid=25268)\u001b[0m lz4 not available, disabling sample compression. This will significantly impact RLlib performance. To install lz4, run `pip install lz4`.\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m 2025-02-17 13:42:09,445\tWARNING algorithm_config.py:4726 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "\u001b[36m(pid=20540)\u001b[0m lz4 not available, disabling sample compression. This will significantly impact RLlib performance. To install lz4, run `pip install lz4`.\n",
      "\u001b[36m(pid=24224)\u001b[0m lz4 not available, disabling sample compression. This will significantly impact RLlib performance. To install lz4, run `pip install lz4`.\n",
      "\u001b[36m(SingleAgentEnvRunner pid=10236)\u001b[0m c:\\Python312\\Lib\\site-packages\\pettingzoo\\utils\\conversions.py:132: UserWarning: The base environment `sumo_rl_v0` does not have a `render_mode` defined.\n",
      "\u001b[36m(SingleAgentEnvRunner pid=10236)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=10236)\u001b[0m Step #0.00 (0ms ?*RT. ?UPS, TraCI: 20ms, vehicles TOT 0 ACT 0 BUF 0)                     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m 2025-02-17 13:42:19,199\tWARNING rl_module.py:419 -- Could not create a Catalog object for your RLModule! If you are not using the new API stack yet, make sure to switch it off in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. All algos use the new stack by default. Ignore this message, if your RLModule does not use a Catalog to build its sub-components.\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m 2025-02-17 13:42:19,200\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m 2025-02-17 13:42:19,200\tWARNING deprecation.py:50 -- DeprecationWarning: `get_rl_module_config` has been deprecated. Use `RLModule(*, observation_space=.., action_space=.., ....)` instead. This will raise an error in the future!\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::SingleAgentEnvRunner.__init__()\u001b[39m (pid=20540, ip=127.0.0.1, actor_id=4089c3ae2aba9a78dab76a9201000000, repr=<ray.rllib.env.single_agent_env_runner.SingleAgentEnvRunner object at 0x0000025591E12690>)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m              ^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\ray\\rllib\\algorithms\\ppo\\torch\\default_ppo_torch_rl_module.py\", line 24, in __init__\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m     super().__init__(*args, **kwargs, catalog_class=catalog_class)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\ray\\rllib\\core\\rl_module\\torch\\torch_rl_module.py\", line 50, in __init__\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m     RLModule.__init__(self, *args, **kwargs)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\ray\\rllib\\core\\rl_module\\rl_module.py\", line 456, in __init__\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m     self.setup()\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\ray\\rllib\\algorithms\\ppo\\default_ppo_rl_module.py\", line 31, in setup\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m     self.catalog.actor_critic_encoder_config.base_encoder_config,\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m AttributeError: 'NoneType' object has no attribute 'actor_critic_encoder_config'\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m \n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m During handling of the above exception, another exception occurred:\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m \n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m \u001b[36mray::SingleAgentEnvRunner.__init__()\u001b[39m (pid=20540, ip=127.0.0.1, actor_id=4089c3ae2aba9a78dab76a9201000000, repr=<ray.rllib.env.single_agent_env_runner.SingleAgentEnvRunner object at 0x0000025591E12690>)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1877, in ray._raylet.execute_task\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1979, in ray._raylet.execute_task\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 1824, in ray._raylet.execute_task.function_executor\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\ray\\rllib\\env\\single_agent_env_runner.py\", line 116, in __init__\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m     self.make_module()\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\ray\\rllib\\env\\single_agent_env_runner.py\", line 695, in make_module\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m     self.module = module_spec.build()\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m                   ^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\ray\\rllib\\core\\rl_module\\rl_module.py\", line 113, in build\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m     module = self.module_class(module_config)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\ray\\rllib\\algorithms\\ppo\\torch\\default_ppo_torch_rl_module.py\", line 24, in __init__\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m     super().__init__(*args, **kwargs, catalog_class=catalog_class)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\ray\\rllib\\core\\rl_module\\torch\\torch_rl_module.py\", line 50, in __init__\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m     RLModule.__init__(self, *args, **kwargs)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\ray\\rllib\\core\\rl_module\\rl_module.py\", line 398, in __init__\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m     deprecation_warning(\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\ray\\rllib\\utils\\deprecation.py\", line 48, in deprecation_warning\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m     raise ValueError(msg)\n",
      "\u001b[36m(SingleAgentEnvRunner pid=20540)\u001b[0m ValueError: `RLModule(config=[RLModuleConfig])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., learner_only=.., model_config=..)` instead.\n",
      "\u001b[36m(SingleAgentEnvRunner pid=10236)\u001b[0m \n",
      "\u001b[36m(SingleAgentEnvRunner pid=10236)\u001b[0m \n",
      "\u001b[36m(SingleAgentEnvRunner pid=24224)\u001b[0m \n",
      "\u001b[36m(SingleAgentEnvRunner pid=24224)\u001b[0m \n",
      "\u001b[36m(PPO pid=25268)\u001b[0m 2025-02-17 13:42:19,387\tERROR actor_manager.py:815 -- Ray error (The actor died because of an error raised in its creation task, \u001b[36mray::SingleAgentEnvRunner.__init__()\u001b[39m (pid=20540, ip=127.0.0.1, actor_id=4089c3ae2aba9a78dab76a9201000000, repr=<ray.rllib.env.single_agent_env_runner.SingleAgentEnvRunner object at 0x0000025591E12690>)\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m \n",
      "\u001b[36m(PPO pid=25268)\u001b[0m \n",
      "\u001b[36m(PPO pid=25268)\u001b[0m ValueError: `RLModule(config=[RLModuleConfig])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., learner_only=.., model_config=..)` instead.), taking actor 1 out of service.\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m 2025-02-17 13:42:19,387\tERROR actor_manager.py:815 -- Ray error (The actor died because of an error raised in its creation task, \u001b[36mray::SingleAgentEnvRunner.__init__()\u001b[39m (pid=24224, ip=127.0.0.1, actor_id=7b9fa7137b1b033f8cb70c5501000000, repr=<ray.rllib.env.single_agent_env_runner.SingleAgentEnvRunner object at 0x000002648D09E870>)\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m \n",
      "\u001b[36m(PPO pid=25268)\u001b[0m \n",
      "\u001b[36m(PPO pid=25268)\u001b[0m ValueError: `RLModule(config=[RLModuleConfig])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., learner_only=.., model_config=..)` instead.), taking actor 2 out of service.\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m 2025-02-17 13:42:19,387\tERROR actor_manager.py:815 -- Ray error (The actor died because of an error raised in its creation task, \u001b[36mray::SingleAgentEnvRunner.__init__()\u001b[39m (pid=10236, ip=127.0.0.1, actor_id=afd7277ced390a8e97f1daaa01000000, repr=<ray.rllib.env.single_agent_env_runner.SingleAgentEnvRunner object at 0x0000024475F5A8D0>)\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m \n",
      "\u001b[36m(PPO pid=25268)\u001b[0m \n",
      "\u001b[36m(PPO pid=25268)\u001b[0m ValueError: `RLModule(config=[RLModuleConfig])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., learner_only=.., model_config=..)` instead.), taking actor 3 out of service.\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m 2025-02-17 13:42:19,387\tERROR actor_manager.py:815 -- Ray error (The actor died because of an error raised in its creation task, \u001b[36mray::SingleAgentEnvRunner.__init__()\u001b[39m (pid=18736, ip=127.0.0.1, actor_id=9d22c81e469c86f4c3ae22f701000000, repr=<ray.rllib.env.single_agent_env_runner.SingleAgentEnvRunner object at 0x000002D5D64EE600>)\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m \n",
      "\u001b[36m(PPO pid=25268)\u001b[0m \n",
      "\u001b[36m(PPO pid=25268)\u001b[0m ValueError: `RLModule(config=[RLModuleConfig])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., learner_only=.., model_config=..)` instead.), taking actor 4 out of service.\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m 2025-02-17 13:42:19,387\tERROR env_runner_group.py:826 -- Validation of EnvRunner failed! Error=The actor died because of an error raised in its creation task, \u001b[36mray::SingleAgentEnvRunner.__init__()\u001b[39m (pid=20540, ip=127.0.0.1, actor_id=4089c3ae2aba9a78dab76a9201000000, repr=<ray.rllib.env.single_agent_env_runner.SingleAgentEnvRunner object at 0x0000025591E12690>)\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m \n",
      "\u001b[36m(PPO pid=25268)\u001b[0m \n",
      "\u001b[36m(PPO pid=25268)\u001b[0m 2025-02-17 13:42:19,387\tERROR env_runner_group.py:826 -- Validation of EnvRunner failed! Error=The actor died because of an error raised in its creation task, \u001b[36mray::SingleAgentEnvRunner.__init__()\u001b[39m (pid=24224, ip=127.0.0.1, actor_id=7b9fa7137b1b033f8cb70c5501000000, repr=<ray.rllib.env.single_agent_env_runner.SingleAgentEnvRunner object at 0x000002648D09E870>)\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m \n",
      "\u001b[36m(PPO pid=25268)\u001b[0m \n",
      "\u001b[36m(PPO pid=25268)\u001b[0m 2025-02-17 13:42:19,387\tERROR env_runner_group.py:826 -- Validation of EnvRunner failed! Error=The actor died because of an error raised in its creation task, \u001b[36mray::SingleAgentEnvRunner.__init__()\u001b[39m (pid=10236, ip=127.0.0.1, actor_id=afd7277ced390a8e97f1daaa01000000, repr=<ray.rllib.env.single_agent_env_runner.SingleAgentEnvRunner object at 0x0000024475F5A8D0>)\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m \n",
      "\u001b[36m(PPO pid=25268)\u001b[0m \n",
      "\u001b[36m(PPO pid=25268)\u001b[0m 2025-02-17 13:42:19,387\tERROR env_runner_group.py:826 -- Validation of EnvRunner failed! Error=The actor died because of an error raised in its creation task, \u001b[36mray::SingleAgentEnvRunner.__init__()\u001b[39m (pid=18736, ip=127.0.0.1, actor_id=9d22c81e469c86f4c3ae22f701000000, repr=<ray.rllib.env.single_agent_env_runner.SingleAgentEnvRunner object at 0x000002D5D64EE600>)\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m \n",
      "\u001b[36m(PPO pid=25268)\u001b[0m \n",
      "\u001b[36m(SingleAgentEnvRunner pid=18736)\u001b[0m \n",
      "\u001b[36m(SingleAgentEnvRunner pid=18736)\u001b[0m \n",
      "\u001b[36m(PPO pid=25268)\u001b[0m Error: File '4x4.net.xml' is not accessible (No such file or directory).\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m Quitting (on error).\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::PPO.__init__()\u001b[39m (pid=25268, ip=127.0.0.1, actor_id=cfaa7153779c40f507e0620701000000, repr=PPO(env=4x4grid; env-runners=4; learners=0; multi-agent=False))\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m     super().__init__(\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m     self.setup(copy.deepcopy(self.config))\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m     self.env_runner_group = EnvRunnerGroup(\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m                             ^^^^^^^^^^^^^^^\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m     self._setup(\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\ray\\rllib\\env\\env_runner_group.py\", line 291, in _setup\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m     self._local_env_runner = self._make_worker(\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\ray\\rllib\\env\\env_runner_group.py\", line 1187, in _make_worker\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m     worker = cls(\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m              ^^^^\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m     self.make_env()\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\ray\\rllib\\env\\single_agent_env_runner.py\", line 658, in make_env\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m     gym.make_vec(\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\gymnasium\\envs\\registration.py\", line 918, in make_vec\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m     env = gym.vector.SyncVectorEnv(\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m     self.envs = [env_fn() for env_fn in env_fns]\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m                  ^^^^^^^^\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\gymnasium\\envs\\registration.py\", line 903, in create_single_env\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m     single_env = make(env_spec, **env_spec_kwargs.copy())\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\gymnasium\\envs\\registration.py\", line 740, in make\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m     env = env_creator(**env_spec_kwargs)\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m   File \"C:\\Users\\shrof\\AppData\\Local\\Temp\\ipykernel_24992\\3365516881.py\", line 38, in <lambda>\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\pettingzoo\\utils\\conversions.py\", line 14, in par_fn\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m     env = env_fn(**kwargs)\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m           ^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m   File \"c:\\Python312\\Lib\\site-packages\\sumo_rl\\environment\\env.py\", line 32, in env\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m     env = SumoEnvironmentPZ(**kwargs)\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m     self.env = SumoEnvironment(**self._kwargs)\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m     traci.start([sumolib.checkBinary(\"sumo\"), \"-n\", self._net], label=\"init_connection\" + self.label)\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m   File \"C:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\main.py\", line 147, in start\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m     result = init(sumoPort, numRetries, \"localhost\", label, sumoProcess, doSwitch, traceFile, traceGetters)\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m   File \"C:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\main.py\", line 119, in init\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m     return con.getVersion()\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m            ^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m   File \"C:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\connection.py\", line 382, in getVersion\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m     result = self._sendCmd(command, None, None)\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m   File \"C:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\connection.py\", line 232, in _sendCmd\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m     return self._sendExact()\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m            ^^^^^^^^^^^^^^^^^\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m   File \"C:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\connection.py\", line 137, in _sendExact\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m     raise FatalTraCIError(\"Connection closed by SUMO.\")\n",
      "\u001b[36m(PPO pid=25268)\u001b[0m traci.exceptions.FatalTraCIError: Connection closed by SUMO.\n",
      "2025-02-17 13:42:19,952\tERROR tune_controller.py:1331 -- Trial task failed for trial PPO_4x4grid_e1e2f_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\ray\\air\\execution\\_internal\\event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\ray\\_private\\auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\ray\\_private\\worker.py\", line 2772, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\ray\\_private\\worker.py\", line 921, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.ActorDiedError: The actor died because of an error raised in its creation task, \u001b[36mray::PPO.__init__()\u001b[39m (pid=25268, ip=127.0.0.1, actor_id=cfaa7153779c40f507e0620701000000, repr=PPO(env=4x4grid; env-runners=4; learners=0; multi-agent=False))\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1883, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 1824, in ray._raylet.execute_task.function_executor\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\ray\\_private\\function_manager.py\", line 696, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py\", line 590, in __init__\n",
      "    super().__init__(\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\ray\\tune\\trainable\\trainable.py\", line 158, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 463, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py\", line 693, in setup\n",
      "    self.env_runner_group = EnvRunnerGroup(\n",
      "                            ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\ray\\rllib\\env\\env_runner_group.py\", line 196, in __init__\n",
      "    self._setup(\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\ray\\rllib\\env\\env_runner_group.py\", line 291, in _setup\n",
      "    self._local_env_runner = self._make_worker(\n",
      "                             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\ray\\rllib\\env\\env_runner_group.py\", line 1187, in _make_worker\n",
      "    worker = cls(\n",
      "             ^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\ray\\rllib\\env\\single_agent_env_runner.py\", line 98, in __init__\n",
      "    self.make_env()\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\ray\\rllib\\env\\single_agent_env_runner.py\", line 658, in make_env\n",
      "    gym.make_vec(\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\gymnasium\\envs\\registration.py\", line 918, in make_vec\n",
      "    env = gym.vector.SyncVectorEnv(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\gymnasium\\vector\\sync_vector_env.py\", line 86, in __init__\n",
      "    self.envs = [env_fn() for env_fn in env_fns]\n",
      "                 ^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\gymnasium\\envs\\registration.py\", line 903, in create_single_env\n",
      "    single_env = make(env_spec, **env_spec_kwargs.copy())\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\gymnasium\\envs\\registration.py\", line 740, in make\n",
      "    env = env_creator(**env_spec_kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\shrof\\AppData\\Local\\Temp\\ipykernel_24992\\3365516881.py\", line 38, in <lambda>\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\pettingzoo\\utils\\conversions.py\", line 14, in par_fn\n",
      "    env = env_fn(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\sumo_rl\\environment\\env.py\", line 32, in env\n",
      "    env = SumoEnvironmentPZ(**kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\sumo_rl\\environment\\env.py\", line 519, in __init__\n",
      "    self.env = SumoEnvironment(**self._kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Python312\\Lib\\site-packages\\sumo_rl\\environment\\env.py\", line 149, in __init__\n",
      "    traci.start([sumolib.checkBinary(\"sumo\"), \"-n\", self._net], label=\"init_connection\" + self.label)\n",
      "  File \"C:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\main.py\", line 147, in start\n",
      "    result = init(sumoPort, numRetries, \"localhost\", label, sumoProcess, doSwitch, traceFile, traceGetters)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\main.py\", line 119, in init\n",
      "    return con.getVersion()\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\connection.py\", line 382, in getVersion\n",
      "    result = self._sendCmd(command, None, None)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\connection.py\", line 232, in _sendCmd\n",
      "    return self._sendExact()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files (x86)\\Eclipse\\Sumo\\tools\\traci\\connection.py\", line 137, in _sendExact\n",
      "    raise FatalTraCIError(\"Connection closed by SUMO.\")\n",
      "traci.exceptions.FatalTraCIError: Connection closed by SUMO.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name             </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_4x4grid_e1e2f_00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-17 13:42:19,968\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/shrof/ray_results/4x4grid/PPO' in 0.0156s.\n",
      "\u001b[36m(SingleAgentEnvRunner pid=10236)\u001b[0m Error: tcpip::Socket::recvAndCheck @ recv: Socket reset by peer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=10236)\u001b[0m Step #0.00\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [PPO_4x4grid_e1e2f_00000])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 70\u001b[0m\n\u001b[0;32m     35\u001b[0m register_env(\n\u001b[0;32m     36\u001b[0m     env_name,\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m _: ParallelPettingZooEnv(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m     ),\n\u001b[0;32m     46\u001b[0m )\n\u001b[0;32m     48\u001b[0m config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     49\u001b[0m     PPOConfig()\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;241m.\u001b[39menvironment(env\u001b[38;5;241m=\u001b[39menv_name, disable_env_checking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;241m.\u001b[39mresources(num_gpus\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRLLIB_NUM_GPUS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[0;32m     68\u001b[0m )\n\u001b[1;32m---> 70\u001b[0m \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPPO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPPO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimesteps_total\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m~/ray_results/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menv_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\ray\\tune\\tune.py:1035\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m incomplete_trials:\n\u001b[0;32m   1034\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_failed_trial \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment_interrupted_event\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[1;32m-> 1035\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TuneError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrials did not complete\u001b[39m\u001b[38;5;124m\"\u001b[39m, incomplete_trials)\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1037\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrials did not complete: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, incomplete_trials)\n",
      "\u001b[1;31mTuneError\u001b[0m: ('Trials did not complete', [PPO_4x4grid_e1e2f_00000])"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=24224)\u001b[0m Step #0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=18736)\u001b[0m Error: tcpip::Socket::recvAndCheck @ recv: Socket reset by peer\n",
      "\u001b[36m(SingleAgentEnvRunner pid=18736)\u001b[0m Quitting (on error).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "if \"SUMO_HOME\" in os.environ:\n",
    "    tools = os.path.join(os.environ[\"SUMO_HOME\"], \"tools\")\n",
    "    sys.path.append(tools)\n",
    "else:\n",
    "    sys.exit(\"Please declare the environment variable 'SUMO_HOME'\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ray\n",
    "import traci\n",
    "from ray import tune\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "from ray.rllib.env.wrappers.pettingzoo_env import ParallelPettingZooEnv\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "import sumo_rl\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Use:\n",
    "    # ray[rllib]==2.7.0\n",
    "    # numpy == 1.23.4\n",
    "    # Pillow>=9.4.0\n",
    "    # ray[rllib]==2.7.0\n",
    "    # SuperSuit>=3.9.0\n",
    "    # torch>=1.13.1\n",
    "    # tensorflow-probability>=0.19.0\n",
    "    ray.init()\n",
    "\n",
    "    env_name = \"4x4grid\"\n",
    "\n",
    "    register_env(\n",
    "        env_name,\n",
    "        lambda _: ParallelPettingZooEnv(\n",
    "            sumo_rl.parallel_env(\n",
    "                net_file=\"4x4.net.xml\",\n",
    "                route_file=\"4x4c1c2c1c2.rou.xml\",\n",
    "                out_csv_name=\"outputs/4x4grid/ppo\",\n",
    "                use_gui=False,\n",
    "                num_seconds=1000,\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    config = (\n",
    "        PPOConfig()\n",
    "        .environment(env=env_name, disable_env_checking=True)\n",
    "        .env_runners(num_env_runners=4, rollout_fragment_length=128)\n",
    "        .training(\n",
    "            train_batch_size=512,\n",
    "            lr=2e-5,\n",
    "            gamma=0.95,\n",
    "            lambda_=0.9,\n",
    "            use_gae=True,\n",
    "            clip_param=0.4,\n",
    "            grad_clip=None,\n",
    "            entropy_coeff=0.1,\n",
    "            vf_loss_coeff=0.25,\n",
    "            minibatch_size=64,\n",
    "            num_sgd_iter=10,\n",
    "        )\n",
    "        .debugging(log_level=\"ERROR\")\n",
    "        .framework(framework=\"torch\")\n",
    "        .resources(num_gpus=int(os.environ.get(\"RLLIB_NUM_GPUS\", \"0\")))\n",
    "    )\n",
    "\n",
    "    tune.run(\n",
    "        \"PPO\",\n",
    "        name=\"PPO\",\n",
    "        stop={\"timesteps_total\": 100},\n",
    "        checkpoint_freq=10,\n",
    "        storage_path=\"~/ray_results/\" + env_name,\n",
    "        config=config.to_dict(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
